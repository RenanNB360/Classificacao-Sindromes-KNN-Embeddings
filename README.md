# Classifica√ß√£o de S√≠ndromes com KNN e Embeddings

Este reposit√≥rio cont√©m um projeto onde eu exploro a classifica√ß√£o de s√≠ndromes a partir de embeddings de imagens.  
A ideia foi pegar os vetores de caracter√≠sticas j√° extra√≠dos, organizar os dados e aplicar um pipeline simples, mas completo, para entender a qualidade desses embeddings.

---

# üß† Relat√≥rio de An√°lise de Embeddings e Classifica√ß√£o utilizando KNN

## 1. Metodologia

### üéØ Objetivo
Explorar a capacidade de **embeddings pr√©-treinados** para distinguir entre diferentes **s√≠ndromes**, utilizando um pipeline de classifica√ß√£o baseado no **algoritmo K-Nearest Neighbors (KNN)**.

O objetivo principal foi avaliar o desempenho de diferentes **m√©tricas de dist√¢ncia** (*Euclidiana* e *Cosseno*) e identificar a **configura√ß√£o √≥tima do KNN**.

---

### üßπ Pr√©-processamento dos Dados
Os dados foram carregados a partir do arquivo `mini_gm_public_v0.1.p`, que consiste em um dicion√°rio aninhado com:
- identificadores de s√≠ndrome, sujeito e imagem,  
- e seus respectivos **vetores de embedding**.

O primeiro passo foi ‚Äúaplanar‚Äù essa estrutura em um **DataFrame do Pandas**, onde cada linha representa uma imagem com sua s√≠ndrome associada e o vetor correspondente.

**Etapas e observa√ß√µes:**
- Realizada **An√°lise Explorat√≥ria dos Dados (EDA)**.  
- Nenhum **valor ausente** encontrado.  
- **Distribui√ß√£o equilibrada** das imagens por s√≠ndrome.  
- **Dimens√£o dos embeddings:** 320.  

---

### üåà Visualiza√ß√£o de Embeddings com t-SNE

![TSNE](imagens/tsne.png)

Utilizei **t-Distributed Stochastic Neighbor Embedding (t-SNE)** para projetar os embeddings em 2D.

> üé® Resultado: surgiram alguns clusters bem definidos, mas com **sobreposi√ß√£o significativa**.  
> Isso indica que os embeddings capturam informa√ß√£o discriminativa, **mas n√£o de forma perfeitamente separ√°vel**.

---

### ‚öôÔ∏è Escolha do Algoritmo e Par√¢metros
Optei pelo **KNN** pela sua **simplicidade**, **interpretabilidade** e adequa√ß√£o a problemas baseados em dist√¢ncia.

Implementei uma **vers√£o customizada** do algoritmo que:
- permite alternar entre **dist√¢ncias Euclidiana e Cosseno**,  
- e calcula **probabilidades de classe** pela propor√ß√£o de vizinhos.

#### üî¢ Hiperpar√¢metro *k*
- Utilizada **valida√ß√£o cruzada estratificada com 10 folds**.  
- Testados valores de *k* entre **1 e 15**.  
- **M√©trica principal:** *F1-score macro*, por equilibrar *precis√£o* e *recall*.

---

### üìà M√©tricas de Avalia√ß√£o
As m√©tricas utilizadas foram:

- **AUC-ROC** ‚Üí mede a capacidade do modelo de distinguir classes.  
- **F1-score (macro average)** ‚Üí usada na escolha de *k* e compara√ß√£o entre dist√¢ncias.  
- **Top-5 Accuracy** ‚Üí propor√ß√£o de vezes em que a classe verdadeira est√° entre as 5 mais prov√°veis.  
  > üí° √ötil em cen√°rios de recomenda√ß√£o ou diagn√≥stico assistido.

---

## 2. Resultados

### üîç Visualiza√ß√£o t-SNE
A visualiza√ß√£o mostrou **separa√ß√£o parcial entre s√≠ndromes**:  
clusters distintos, por√©m com **sobreposi√ß√£o**.  
> ‚úÖ Os embeddings carregam informa√ß√£o √∫til, mas n√£o perfeitamente separ√°vel.

---

### üìä Curvas ROC ‚Äì Dist√¢ncia do Cosseno

![Curva ROC Cosseno](imagens/grafico_do_Cosseno.png)

Com a **dist√¢ncia do Cosseno**, o desempenho foi **s√≥lido**:
- **AUCs entre 0.89 e 0.98**,  
- maioria acima de **0.90**.

> Isso indica que os embeddings, combinados com a similaridade de Cosseno, **distinguem bem as s√≠ndromes**.

---

### üìà Curvas ROC ‚Äì Dist√¢ncia Euclidiana

![Curva ROC Euclidiana](imagens/grafico_Euclidiana.png)

A **dist√¢ncia Euclidiana** tamb√©m teve bons resultados:
- **AUCs entre 0.84 e 0.97**,  
- ligeiramente inferiores em algumas classes (ex: `700018215`: 0.84 vs 0.89 no Cosseno).

---

### üßæ Resumo de Desempenho por Dist√¢ncia

| Tipo de Dist√¢ncia | K √ìtimo | AUC M√©dio | F1 M√©dio | Top-5 Accuracy |
|--------------------|---------|------------|-----------|----------------|
| **Euclidiana** | 15 | 0.9178 | 0.6835 | 0.9366 |
| **Cosseno** | 7 | 0.9364 | 0.7454 | 0.9499 |

> üîπ O Cosseno superou a Euclidiana em **todas as m√©tricas**.

---

## 3. An√°lise

- **F1 m√©dio:** 0.7454 (Cosseno) vs 0.6835 (Euclidiana)  
- **AUC m√©dio:** 0.9364 vs 0.9178  
- **Top-5 Accuracy:** 0.9499 vs 0.9366  

üìå **Conclus√£o:**  
O **Cosseno** √© mais adequado para embeddings, pois mede **√¢ngulo entre vetores**, relevante em espa√ßos normalizados.

Al√©m disso:
- O **k √≥timo menor** (7 contra 15) indica **vizinhan√ßas mais coesas**.  
- **Top-5 Accuracy acima de 93%** mostra alta capacidade de incluir a classe correta nas 5 primeiras op√ß√µes.

---

## 4. Desafios e Solu√ß√µes

### ‚ö†Ô∏è Principais desafios
- Garantir **robustez na avalia√ß√£o** ‚Üí resolvido com **valida√ß√£o cruzada estratificada**.  
- Definir **valor ideal de k** ‚Üí resolvido com **busca entre 1 e 15** e sele√ß√£o baseada em F1 macro.  
- Necessidade de **vers√£o customizada do KNN** ‚Üí permitiu c√°lculos flex√≠veis e an√°lise detalhada (curvas ROC e Top-K Accuracy).

---

## 5. Recomenda√ß√µes

1. üîç **Explorar outros classificadores:**  
   SVM, Random Forest, MLP ‚Äî podem oferecer **melhor desempenho ou generaliza√ß√£o**.

2. ‚öôÔ∏è **Otimizar hiperpar√¢metros:**  
   Usar **grid search** ou **random search** mais amplo, aliado √† valida√ß√£o cruzada.

3. üßæ **An√°lise de erros por classe:**  
   Criar **matriz de confus√£o m√©dia** para identificar s√≠ndromes mais confundidas.

4. ‚öñÔ∏è **Avaliar cen√°rios com desequil√≠brio:**  
   Testar t√©cnicas como **SMOTE** ou **pesos de classe**.

5. üß† **Interpretabilidade dos embeddings:**  
   Aplicar **SHAP** ou **LIME** para entender o que diferencia as s√≠ndromes.

6. üìà **Aumento de dados:**  
   Expandir o dataset para **melhorar a robustez** dos resultados.

---

## üèÅ Conclus√£o

O estudo confirmou a **efic√°cia dos embeddings combinados com KNN** na classifica√ß√£o de s√≠ndromes.

> üöÄ A **dist√¢ncia do Cosseno** apresentou o **melhor desempenho geral**, oferecendo uma **base s√≥lida para futuras an√°lises e aprimoramentos**.

---

## O que eu implementei

- **Carregamento dos dados**: uso arquivos `.p` no formato pickle e transformo em um DataFrame bem estruturado com pandas.
- **An√°lise explorat√≥ria**: verifico a quantidade de s√≠ndromes, a distribui√ß√£o das imagens por classe e aponto se existe desbalanceamento.
- **Visualiza√ß√£o**: aplico **t-SNE** para reduzir os embeddings e gerar uma visualiza√ß√£o em 2D dos clusters de s√≠ndromes.
- **Classifica√ß√£o com KNN**:
  - Testo diferentes valores de `k` e duas m√©tricas de dist√¢ncia: **euclidiana** e **cosseno**.
  - Uso valida√ß√£o cruzada estratificada para garantir uma avalia√ß√£o justa entre as classes.
- **M√©tricas de avalia√ß√£o**:
  - AUC (√°rea sob a curva ROC)
  - F1-Score (macro)
  - Top-k Accuracy (top-5 no meu caso)
- **Resultados**:
  - Gr√°ficos de curvas ROC m√©dias por classe
  - Tabelas com m√©dias de AUC, F1 e Top-5 Accuracy
  - Melhor valor de `k` para cada m√©trica de dist√¢ncia

---

## Estrutura do pipeline

1. **Carrego e organizo os dados**  
2. **Fa√ßo EDA (an√°lise explorat√≥ria)**  
3. **Visualizo embeddings com t-SNE**  
4. **Treino e avalio modelos KNN (com dist√¢ncia euclidiana e cosseno)**  
5. **Gero m√©tricas, tabelas e gr√°ficos**  

---

## Como rodar o projeto

Siga os passos abaixo para configurar o ambiente e executar a aplica√ß√£o:

1. **Crie um ambiente virtual em Python**  
   O ambiente virtual garante que as depend√™ncias do projeto fiquem isoladas.  
   ```bash
   python -m venv .venv
   ```

2. **Ative o ambiente virtual**
  - **Linux/MacOS:**
  ```bash
  source .venv/bin/activate
  ```

  - **Windows PowerShell:**
  ```bash
  .venv\Scripts\Activate
  ```

3. **Instale as depend√™ncias do projeto**
  ```bash
  pip install -r requirements.txt
  ```

4. **Execute o projeto**
  ```bash
  python main.py
  ```

